import streamlit as st
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

load_dotenv()

# -----------------------------
# å°‚é–€å®¶å®šç¾©ï¼ˆA/Bï¼‰
# -----------------------------
EXPERTS = {
    "A": {
        "label": "Aï¼šã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒ",
        "desc": "è»¢è·ãƒ»å­¦ç¿’è¨ˆç”»ãƒ»ä¸å®‰ã®æ•´ç†ãŒå¾—æ„ã€‚çŠ¶æ³æ•´ç†â†’å„ªå…ˆé †ä½â†’æ¬¡ã®ä¸€æ­©ã‚’ææ¡ˆã—ã¾ã™ã€‚",
        "system": (
            "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒã§ã™ã€‚"
            "ç›¸è«‡è€…ã®çŠ¶æ³ã‚’ä¸å¯§ã«æ•´ç†ã—ã€å®‰å¿ƒæ„Ÿã®ã‚ã‚‹è¨€è‘‰ã§ã€"
            "å…·ä½“çš„ãªè¡Œå‹•ãƒ—ãƒ©ãƒ³ï¼ˆä»Šæ—¥ã§ãã‚‹ä¸€æ­©ï¼‰ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
            "å¿…è¦ã«å¿œã˜ã¦è³ªå•ã‚‚1ã€œ3å€‹ã ã‘è¿”ã—ã¦ãã ã•ã„ã€‚"
        ),
    },
    "B": {
        "label": "Bï¼šAIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢",
        "desc": "ç”ŸæˆAI/LLMé–‹ç™ºãŒå¾—æ„ã€‚å®Ÿè£…æ‰‹é †ãƒ»è½ã¨ã—ç©´ãƒ»ãƒ‡ãƒãƒƒã‚°ã®è¦³ç‚¹ã§å›ç­”ã—ã¾ã™ã€‚",
        "system": (
            "ã‚ãªãŸã¯ã‚·ãƒ‹ã‚¢AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚"
            "å›ç­”ã¯æŠ€è¡“çš„ã«æ­£ç¢ºã«ã€æ‰‹é †ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ã€"
            "æ³¨æ„ç‚¹ï¼ˆã‚ˆãã‚ã‚‹ãƒŸã‚¹ï¼‰ã¨ç¢ºèªã‚³ãƒãƒ³ãƒ‰ä¾‹ã‚‚æ·»ãˆã¦ãã ã•ã„ã€‚"
            "ä¸ç¢ºã‹ãªå ´åˆã¯æ¨æ¸¬ã›ãšã€å‰ææ¡ä»¶ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        ),
    },
}


# -----------------------------
# LLMå‘¼ã³å‡ºã—é–¢æ•°ï¼ˆæå‡ºè¦ä»¶ï¼‰
# -----------------------------
def ask_llm(user_text: str, expert_type: str) -> str:
    expert = EXPERTS.get(expert_type, EXPERTS["A"])

    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.7,
    )

    messages = [
        SystemMessage(content=expert["system"]),
        HumanMessage(content=user_text),
    ]

    result = llm.invoke(messages)
    return result.content


# -----------------------------
# UI
# -----------------------------
st.set_page_config(page_title="Expert Switch LLM App", page_icon="ğŸ¤–", layout="centered")

st.title("ğŸ¤– Expert Switch LLM App")
st.caption("å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’åˆ‡ã‚Šæ›¿ãˆã¦ã€åŒã˜è³ªå•ã§ã‚‚è¦³ç‚¹ã®é•ã†å›ç­”ã‚’å¾—ã‚‰ã‚Œã‚‹Streamlitã‚¢ãƒ—ãƒªã§ã™ã€‚")

with st.expander("ã“ã®ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦ / ä½¿ã„æ–¹", expanded=True):
    st.markdown(
        """
**ã§ãã‚‹ã“ã¨**
- å…¥åŠ›ã—ãŸè³ªå•ã‚’LLMã«æ¸¡ã—ã€å›ç­”ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
- ã€Œå°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã€ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã“ã¨ã§ã€å›ç­”ã®è¦–ç‚¹ãƒ»å£èª¿ãƒ»å‡ºåŠ›å½¢å¼ãŒå¤‰ã‚ã‚Šã¾ã™ã€‚

**ä½¿ã„æ–¹**
1. å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ï¼ˆA/Bï¼‰ã‚’é¸ã¶  
2. å…¥åŠ›æ¬„ã«è³ªå•ã‚’å…¥åŠ›ã™ã‚‹  
3. ã€Œé€ä¿¡ã€ã‚’æŠ¼ã™  
"""
    )

st.subheader("å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’é¸ã‚“ã§ã­")
expert_type = st.radio(
    label="",
    options=["A", "B"],
    format_func=lambda x: EXPERTS[x]["label"],
    horizontal=True,
)

st.info(f"**{EXPERTS[expert_type]['label']}**ï¼š{EXPERTS[expert_type]['desc']}")

user_text = st.text_area("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ", placeholder="ä¾‹ï¼šStreamlit Cloudã§Secretsã¯ã©ã“ã«è¨­å®šã™ã‚‹ï¼Ÿ", height=100)
send = st.button("é€ä¿¡")

if send:
    if not user_text.strip():
        st.warning("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥ã‚Œã¦ã­ã€‚")
    else:
        with st.spinner("è€ƒãˆä¸­..."):
            try:
                answer = ask_llm(user_text, expert_type)
                st.subheader("LLMã®å›ç­”")
                st.write(answer)
            except Exception as e:
                st.error("LLMå‘¼ã³å‡ºã—ã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸã‚ˆã€‚APIã‚­ãƒ¼ã‚„ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ç¢ºèªã—ã¦ã­ã€‚")
                st.exception(e)

st.divider()
st.caption("â€» APIã‚­ãƒ¼ã¯GitHubã«å«ã‚ãšã€ãƒ­ãƒ¼ã‚«ãƒ«ã¯ .env / ãƒ‡ãƒ—ãƒ­ã‚¤å…ˆã¯ Secrets ã§è¨­å®šã—ã¾ã™ã€‚")